{
  "metadata": {
    "version": "2.2.0",
    "lastUpdated": "2026-01-06",
    "description": "AI-utveckling med accelerationsvisualisering - fr√•n AI:s f√∂delse till dagens genombrott",
    "language": "sv",
    "author": "Compiled from verified sources",
    "totalMilestones": 55
  },

  "categories": [
    {"id": "research", "label": "Forskningsgenombrott", "color": "#00d4ff", "icon": "üî¨"},
    {"id": "models", "label": "Modellreleaser", "color": "#7c3aed", "icon": "ü§ñ"},
    {"id": "products", "label": "Produkter & Appar", "color": "#f472b6", "icon": "‚ú®"},
    {"id": "benchmarks", "label": "Benchmark-genombrott", "color": "#10b981", "icon": "üìä"},
    {"id": "tools", "label": "Verktyg & Standarder", "color": "#f59e0b", "icon": "üõ†Ô∏è"},
    {"id": "companies", "label": "F√∂retag & Labs", "color": "#ec4899", "icon": "üè¢"}
  ],

  "companies": [
    {"id": "openai", "name": "OpenAI", "color": "#10a37f"},
    {"id": "anthropic", "name": "Anthropic", "color": "#d4a574"},
    {"id": "google", "name": "Google/DeepMind", "color": "#4285f4"},
    {"id": "meta", "name": "Meta", "color": "#0668e1"},
    {"id": "ibm", "name": "IBM", "color": "#006699"},
    {"id": "mistral", "name": "Mistral AI", "color": "#f2a154"},
    {"id": "midjourney", "name": "Midjourney", "color": "#8b5cf6"},
    {"id": "stability", "name": "Stability AI", "color": "#ec4899"},
    {"id": "cursor", "name": "Cursor", "color": "#000000"},
    {"id": "codeium", "name": "Codeium", "color": "#09b6a3"}
  ],

  "milestones": [
    {
      "id": "dartmouth-1956",
      "title": "Dartmouth-konferensen",
      "date": "1956-06-01",
      "dateDisplay": "Sommar 1956",
      "category": "research",
      "importance": 10,
      "shortDesc": "AI f√∂ds som akademiskt forskningsf√§lt",
      "detailedDesc": "Dartmouth-workshopen 1956 var den h√§ndelse som markerade AI:s formella tillkomst som en akademisk disciplin. John McCarthy, Marvin Minsky, Nathaniel Rochester och Claude Shannon myntade termen 'artificiell intelligens' och definierade f√§ltets m√•l.",
      "significance": "Detta var √∂gonblicket d√• AI fick sitt namn, sitt uppdrag och sina nyckelpersoner. Workshopen lade grunden f√∂r AI som vetenskaplig disciplin och satte ambiti√∂sa m√•l f√∂r framtiden.",
      "capabilityArea": "foundation",
      "beforeAfter": {
        "before": "Datorer s√•gs endast som ber√§kningsverk tyg",
        "after": "AI etablerades som m√•l - att skapa maskiner som kan t√§nka"
      },
      "keyPeople": ["John McCarthy", "Marvin Minsky", "Nathaniel Rochester", "Claude Shannon"],
      "tags": ["grundl√§ggande", "historia", "konferens"],
      "sources": [
        {
          "title": "The Birth of AI: The Dartmouth Conference (1956)",
          "url": "https://ai-researchs.com/the-birth-of-ai-the-dartmouth-conference-1956/",
          "type": "reference"
        },
        {
          "title": "History of Artificial Intelligence - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/History_of_artificial_intelligence",
          "type": "reference"
        }
      ]
    },
    {
      "id": "perceptron-1958",
      "title": "Perceptron - det f√∂rsta neurala n√§tverket",
      "date": "1958-07-01",
      "dateDisplay": "1958",
      "category": "research",
      "importance": 8,
      "shortDesc": "Frank Rosenblatt byggde den f√∂rsta neurala n√§tverksmodellen",
      "detailedDesc": "Perceptron var ett enskikts neuralt n√§tverk som introducerades av Frank Rosenblatt. Det kunde l√§ra sig fr√•n erfarenhet och k√§nna igen enkla m√∂nster - ett stort steg i att l√§ra datorer att anpassa sig och f√∂rb√§ttra sig sj√§lva.",
      "significance": "Perceptron visade att maskiner kunde l√§ra sig fr√•n data och f√∂rb√§ttra sin prestanda √∂ver tid. Detta la grunden f√∂r moderna neurala n√§tverk och deep learning.",
      "capabilityArea": "foundation",
      "beforeAfter": {
        "before": "Datorer kunde bara k√∂ra f√∂rutbest√§mda program",
        "after": "Datorer kunde l√§ra sig fr√•n exempel och f√∂rb√§ttra sig"
      },
      "keyPeople": ["Frank Rosenblatt"],
      "tags": ["neurala n√§tverk", "maskininl√§rning", "grundl√§ggande"],
      "sources": [
        {
          "title": "The Top 20 Milestones in AI (1943 to Present)",
          "url": "https://mediaandthemachine.substack.com/p/the-top-20-milestones-in-ai-1943",
          "type": "reference"
        }
      ]
    },
    {
      "id": "ai-winter-1974",
      "title": "AI-vintern b√∂rjar",
      "date": "1974-01-01",
      "dateDisplay": "1974-1980",
      "category": "research",
      "importance": 6,
      "shortDesc": "Finansieringskollaps visar tidiga AI-begr√§nsningar",
      "detailedDesc": "F√∂rst AI-vintern inleddes n√§r f√∂rv√§ntningarna p√• AI-system inte uppfylldes. Finansiering drogs in n√§r lovande projekt inte levererade praktiska resultat, vilket ledde till minskad forskning i n√§stan ett decennium.",
      "significance": "AI-vintern l√§rde forskare om vikten av realistiska f√∂rv√§ntningar och behovet av solid vetenskaplig grund. Det var en n√∂dv√§ndig korrigering av √∂veroptimism.",
      "capabilityArea": "foundation",
      "keyPeople": ["James Lighthill"],
      "tags": ["historia", "utmaningar", "finansiering"],
      "sources": [
        {
          "title": "History of Artificial Intelligence - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/History_of_artificial_intelligence",
          "type": "reference"
        }
      ]
    },
    {
      "id": "backpropagation-1986",
      "title": "Backpropagation √•teruppt√§cks",
      "date": "1986-10-09",
      "dateDisplay": "1986",
      "category": "research",
      "importance": 8,
      "shortDesc": "Genombrott i hur neurala n√§tverk kan tr√§nas effektivt",
      "detailedDesc": "Backpropagation-algoritmen, som m√∂jligg√∂r tr√§ning av fler-lagers neurala n√§tverk, √•teruppt√§cktes och populariserades. Detta gjorde det m√∂jligt att tr√§na djupare n√§tverk effektivt.",
      "significance": "Backpropagation √§r den fundamentala algoritm som g√∂r modern deep learning m√∂jlig. Utan den skulle dagens AI-revolution inte vara m√∂jlig.",
      "capabilityArea": "foundation",
      "keyPeople": ["David Rumelhart", "Geoffrey Hinton", "Ronald Williams"],
      "tags": ["tr√§ning", "algoritm", "neurala n√§tverk"],
      "sources": [
        {
          "title": "History of Artificial Intelligence - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/History_of_artificial_intelligence",
          "type": "reference"
        }
      ]
    },
    {
      "id": "deep-blue-1997",
      "title": "Deep Blue besegrar Kasparov",
      "date": "1997-05-11",
      "dateDisplay": "11 Maj 1997",
      "category": "benchmarks",
      "company": "ibm",
      "importance": 9,
      "shortDesc": "F√∂rsta g√•ngen en dator besegrade v√§rldsm√§stare i schack",
      "detailedDesc": "IBM:s Deep Blue-superdator besegrade Garry Kasparov, v√§rldsm√§staren i schack, den 11 maj 1997. Deep Blue kunde ber√§kna miljontals drag per sekund och visade att datorer kunde √∂vertr√§ffa m√§nniskor i komplexa strategiska spel.",
      "significance": "Detta var ett symboliskt √∂gonblick som visade att datorer kunde matcha och √∂vertr√§ffa m√§nsklig intelligens i specifika dom√§ner. Det inspirerade en generation av AI-forskare.",
      "capabilityArea": "games",
      "beforeAfter": {
        "before": "Schack ans√•gs vara f√∂r komplext f√∂r datorer",
        "after": "AI visade √∂verl√§gsen f√∂rm√•ga i strategiska spel"
      },
      "metrics": [
        {"name": "Ber√§kningar per sekund", "value": "Miljoner", "comparison": "vs m√§nsklig intuition"}
      ],
      "keyPeople": ["Garry Kasparov", "Murray Campbell", "Feng-hsiung Hsu"],
      "tags": ["schack", "spel", "benchmark"],
      "sources": [
        {
          "title": "The Top 20 Milestones in AI",
          "url": "https://mediaandthemachine.substack.com/p/the-top-20-milestones-in-ai-1943",
          "type": "reference"
        }
      ]
    },
    {
      "id": "imagenet-2009",
      "title": "ImageNet-dataset skapas",
      "date": "2009-06-01",
      "dateDisplay": "2009",
      "category": "research",
      "importance": 7,
      "shortDesc": "Massiv bilddatabas l√§gger grunden f√∂r datorseende",
      "detailedDesc": "ImageNet-datasetet, med miljontals m√§rkta bilder, skapades f√∂r att tr√§na och testa datorseendesystem. Det blev den viktigaste benchmarken f√∂r bildklassificering.",
      "significance": "ImageNet-datasetet m√∂jliggjorde tr√§ning av stora neurala n√§tverk f√∂r bildanalys och blev katalysatorn f√∂r deep learning-revolutionen.",
      "capabilityArea": "vision",
      "keyPeople": ["Fei-Fei Li"],
      "tags": ["dataset", "datorseende", "benchmark"],
      "sources": [
        {
          "title": "History of Artificial Intelligence - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/History_of_artificial_intelligence",
          "type": "reference"
        }
      ]
    },
    {
      "id": "alexnet-2012",
      "title": "AlexNet vinner ImageNet",
      "date": "2012-10-01",
      "dateDisplay": "Oktober 2012",
      "category": "benchmarks",
      "importance": 10,
      "shortDesc": "Deep learning-eran b√∂rjar med kraftig f√∂rb√§ttring i bildklassificering",
      "detailedDesc": "AlexNet, ett djupt faltningsneuralt n√§tverk utvecklat av Alex Krizhevsky, vann ImageNet-t√§vlingen med betydligt f√§rre fel √§n tv√•a. Detta markerade en v√§ndpunkt d√§r deep learning visade sin √∂verl√§gsna f√∂rm√•ga.",
      "significance": "AlexNet-vinsten var startskottet f√∂r deep learning-revolutionen. Det visade att djupa neurala n√§tverk med GPU-tr√§ning kunde √∂vertr√§ffa alla tidigare metoder.",
      "capabilityArea": "vision",
      "beforeAfter": {
        "before": "Bildklassificering var l√•ngsam och oprecis",
        "after": "Deep learning visade dramatisk f√∂rb√§ttring i noggrannhet"
      },
      "metrics": [
        {"name": "Felfrekvens", "value": "16.4%", "comparison": "vs 26% f√∂r n√§st b√§sta 2012"}
      ],
      "keyPeople": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey Hinton"],
      "tags": ["deep learning", "datorseende", "genombrott"],
      "sources": [
        {
          "title": "The Top 20 Milestones in AI",
          "url": "https://mediaandthemachine.substack.com/p/the-top-20-milestones-in-ai-1943",
          "type": "reference"
        }
      ]
    },
    {
      "id": "word2vec-2013",
      "title": "Word2Vec - ordrepresentationer",
      "date": "2013-01-01",
      "dateDisplay": "2013",
      "category": "research",
      "company": "google",
      "importance": 7,
      "shortDesc": "Genombrott i hur ord kan representeras matematiskt",
      "detailedDesc": "Word2Vec-tekniken fr√•n Google m√∂jliggjorde att representera ord som vektorer i ett matematiskt rum d√§r semantiska relationer bevaras. Detta la grunden f√∂r modern spr√•kf√∂rst√•else.",
      "significance": "Word2Vec visade att betydelse kan f√•ngas matematiskt och att datorer kan f√∂rst√• semantiska relationer mellan ord.",
      "capabilityArea": "language",
      "keyPeople": ["Tomas Mikolov"],
      "tags": ["NLP", "spr√•k", "embeddings"],
      "sources": [
        {
          "title": "History of Artificial Intelligence",
          "url": "https://en.wikipedia.org/wiki/History_of_artificial_intelligence",
          "type": "reference"
        }
      ]
    },
    {
      "id": "attention-2017",
      "title": "Attention Is All You Need - Transformers uppfinns",
      "date": "2017-06-12",
      "dateDisplay": "Juni 2017",
      "category": "research",
      "company": "google",
      "importance": 10,
      "shortDesc": "Transformer-arkitekturen revolutionerar AI",
      "detailedDesc": "Forskare fr√•n Google introducerade Transformer-arkitekturen som baseras helt p√• attention-mekanismer, utan behov av rekurrens. Detta blev grunden f√∂r alla moderna spr√•kmodeller.",
      "significance": "Transformers √§r den viktigaste arkitektoniska innovationen i modern AI. All dagens stora modeller (GPT, BERT, Claude, etc.) bygger p√• denna uppt√§ckt.",
      "capabilityArea": "language",
      "beforeAfter": {
        "before": "Spr√•kmodeller var begr√§nsade och l√•ngsamma",
        "after": "Transformers m√∂jliggjorde massiv skalning och parallelltr√§ning"
      },
      "keyPeople": ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit"],
      "tags": ["transformers", "arkitektur", "genombrott"],
      "sources": [
        {
          "title": "Attention Is All You Need - ArXiv",
          "url": "https://arxiv.org/abs/1706.03762",
          "type": "paper"
        },
        {
          "title": "Attention Is All You Need - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/Attention_Is_All_You_Need",
          "type": "reference"
        }
      ]
    },
    {
      "id": "alphago-zero-2017",
      "title": "AlphaGo Zero - sj√§lvl√§rande AI",
      "date": "2017-10-18",
      "dateDisplay": "Oktober 2017",
      "category": "benchmarks",
      "company": "google",
      "importance": 9,
      "shortDesc": "AI l√§r sig spela Go fr√•n noll utan m√§nsklig data",
      "detailedDesc": "AlphaGo Zero fr√•n DeepMind l√§rde sig spela Go enbart genom sj√§lvspel, utan n√•gon m√§nsklig data. Det blev b√§ttre √§n originalet AlphaGo och visade kraften i reinforcement learning.",
      "significance": "Visade att AI kan l√§ra sig komplex strategi helt sj√§lvst√§ndigt, utan m√§nsklig v√§gledning. Detta √∂ppnade d√∂rren f√∂r sj√§lvl√§rande system.",
      "capabilityArea": "games",
      "beforeAfter": {
        "before": "AI beh√∂vde m√§nskliga exempel f√∂r att l√§ra sig",
        "after": "AI kunde l√§ra sig fr√•n noll genom sj√§lvspel"
      },
      "keyPeople": ["David Silver", "Julian Schrittwieser", "Demis Hassabis"],
      "tags": ["reinforcement learning", "spel", "sj√§lvl√§rande"],
      "sources": [
        {
          "title": "70 Years of AI: 57 Key Milestones",
          "url": "https://www.visive.ai/news/70-years-of-ai-57-key-milestones-in-its-astonishing-evolution",
          "type": "reference"
        }
      ]
    },
    {
      "id": "gpt-1-2018",
      "title": "GPT-1 - generativ f√∂rtr√§ning",
      "date": "2018-06-11",
      "dateDisplay": "Juni 2018",
      "category": "models",
      "company": "openai",
      "importance": 8,
      "shortDesc": "OpenAI introducerar generativ f√∂rtr√§ning f√∂r spr√•kmodeller",
      "detailedDesc": "GPT-1 med 117 miljoner parametrar demonstrerade kraften i generativ f√∂rtr√§ning. Modellen tr√§nade p√• ostrukturerad text och kunde sedan finjusteras f√∂r specifika uppgifter.",
      "significance": "GPT-1 etablerade pre-training/fine-tuning-paradigmet som blev standarden f√∂r stora spr√•kmodeller.",
      "capabilityArea": "language",
      "metrics": [
        {"name": "Parametrar", "value": "117M", "comparison": "F√∂rsta GPT-modellen"}
      ],
      "keyPeople": ["Alec Radford"],
      "tags": ["GPT", "spr√•kmodell", "f√∂rtr√§ning"],
      "sources": [
        {
          "title": "Transformer architecture timeline",
          "url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)",
          "type": "reference"
        }
      ]
    },
    {
      "id": "bert-2018",
      "title": "BERT - dubbelriktad f√∂rst√•else",
      "date": "2018-10-11",
      "dateDisplay": "Oktober 2018",
      "category": "models",
      "company": "google",
      "importance": 8,
      "shortDesc": "Google introducerar dubbelriktad spr√•kf√∂rst√•else",
      "detailedDesc": "BERT (Bidirectional Encoder Representations from Transformers) anv√§nder Transformerens encoder f√∂r att skapa dubbelriktade representationer. Detta gav state-of-the-art resultat p√• m√•nga NLP-uppgifter.",
      "significance": "BERT visade att dubbelriktad kontextf√∂rst√•else √§r kraftfull och blev fundamentet f√∂r m√•nga praktiska NLP-applikationer.",
      "capabilityArea": "language",
      "keyPeople": ["Jacob Devlin", "Ming-Wei Chang"],
      "tags": ["BERT", "NLP", "spr√•kf√∂rst√•else"],
      "sources": [
        {
          "title": "10 Things You Need to Know About BERT",
          "url": "https://neptune.ai/blog/bert-and-the-transformer-architecture",
          "type": "blog"
        }
      ]
    },
    {
      "id": "gpt-2-2019",
      "title": "GPT-2 - 'F√∂r farlig att sl√§ppa'",
      "date": "2019-02-14",
      "dateDisplay": "Februari 2019",
      "category": "models",
      "company": "openai",
      "importance": 8,
      "shortDesc": "1.5B-parameter modell v√§cker debatt om AI-s√§kerhet",
      "detailedDesc": "GPT-2 med 1.5 miljarder parametrar genererade s√• √∂vertygande text att OpenAI initialt v√§grade sl√§ppa den helt, av oro f√∂r missbruk. Detta startade diskussionen om ansvarsfull AI-utveckling.",
      "significance": "GPT-2 visade att spr√•kmodeller n√§rmar sig m√§nsklig skrivf√∂rm√•ga och v√§ckte viktiga fr√•gor om AI-s√§kerhet och ansvar.",
      "capabilityArea": "language",
      "beforeAfter": {
        "before": "AI-genererad text var l√§tt att identifiera",
        "after": "AI kunde skriva √∂vertygande, sammanh√§ngande text"
      },
      "metrics": [
        {"name": "Parametrar", "value": "1.5B", "comparison": "vs 117M i GPT-1"}
      ],
      "keyPeople": ["Alec Radford", "Jeff Wu"],
      "tags": ["GPT", "textgenerering", "AI-s√§kerhet"],
      "sources": [
        {
          "title": "Transformer architecture - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)",
          "type": "reference"
        }
      ]
    },
    {
      "id": "alphastar-2019",
      "title": "AlphaStar beh√§rskar StarCraft II",
      "date": "2019-10-30",
      "dateDisplay": "Oktober 2019",
      "category": "benchmarks",
      "company": "google",
      "importance": 7,
      "shortDesc": "AI n√•r grandmaster-niv√• i realtidsstrategi",
      "detailedDesc": "DeepMind's AlphaStar n√•dde grandmaster-niv√• i StarCraft II, ett komplext realtidsstrategispel med ofullst√§ndig information. Detta visade AI:s f√∂rm√•ga att hantera komplex, dynamisk strategi.",
      "significance": "Visade att AI kan hantera realtidsbeslut, l√•ngsiktig planering och os√§kerhet i komplexa milj√∂er.",
      "capabilityArea": "games",
      "keyPeople": ["Oriol Vinyals"],
      "tags": ["spel", "strategi", "reinforcement learning"],
      "sources": [
        {
          "title": "70 Years of AI Milestones",
          "url": "https://www.visive.ai/news/70-years-of-ai-57-key-milestones-in-its-astonishing-evolution",
          "type": "reference"
        }
      ]
    },
    {
      "id": "gpt-3-2020",
      "title": "GPT-3 - 175B parametrar",
      "date": "2020-05-28",
      "dateDisplay": "Maj 2020",
      "category": "models",
      "company": "openai",
      "importance": 10,
      "shortDesc": "Massiv modell demonstrerar few-shot learning",
      "detailedDesc": "GPT-3 med 175 miljarder parametrar visade att skalning av modeller ger kraftfulla emergenta f√∂rm√•gor. Modellen kunde utf√∂ra uppgifter den aldrig tr√§nats p√•, enbart fr√•n n√•gra exempel (few-shot learning).",
      "significance": "GPT-3 var den f√∂rsta modellen som fick allm√§nheten att f√∂rst√• AI:s potential. Det visade att skalning ger kvalitativa genombrott, inte bara kvantitativa f√∂rb√§ttringar.",
      "capabilityArea": "language",
      "beforeAfter": {
        "before": "Modeller beh√∂vde tr√§nas f√∂r varje specifik uppgift",
        "after": "En modell kunde hantera tusentals uppgifter genom few-shot learning"
      },
      "metrics": [
        {"name": "Parametrar", "value": "175B", "comparison": "vs 1.5B i GPT-2"}
      ],
      "keyPeople": ["Tom Brown", "Sam Altman", "Ilya Sutskever"],
      "tags": ["GPT", "skalning", "few-shot learning"],
      "sources": [
        {
          "title": "AlphaFold 2 article comparison",
          "url": "https://daleonai.com/how-alphafold-works",
          "type": "blog"
        }
      ]
    },
    {
      "id": "alphafold2-2020",
      "title": "AlphaFold 2 l√∂ser proteinveckning",
      "date": "2020-11-30",
      "dateDisplay": "November 2020",
      "category": "benchmarks",
      "company": "google",
      "importance": 10,
      "shortDesc": "AI l√∂ser 50-√•rigt vetenskapligt problem",
      "detailedDesc": "DeepMind's AlphaFold 2 vann CASP14-t√§vlingen med en noggrannhet j√§mf√∂rbar med experimentella metoder. Detta ans√•gs vara en l√∂sning p√• det 50-√•riga 'proteinveckningsproblemet'.",
      "significance": "Ett av de mest betydelsefulla vetenskapliga genombrotten med AI. Accelererar l√§kemedelsutveckling och biologisk forskning dramatiskt.",
      "capabilityArea": "science",
      "beforeAfter": {
        "before": "Proteinstrukturbest√§mning tog m√•nader eller √•r",
        "after": "AlphaFold kan f√∂ruts√§ga strukturer p√• minuter med h√∂g noggrannhet"
      },
      "metrics": [
        {"name": "Noggrannhet (median GDT)", "value": "92.4", "comparison": "vs ~40 f√∂r tidigare metoder"}
      ],
      "keyPeople": ["John Jumper", "Demis Hassabis"],
      "tags": ["vetenskap", "proteinveckning", "genombrott"],
      "sources": [
        {
          "title": "AlphaFold - DeepMind",
          "url": "https://deepmind.google/science/alphafold/",
          "type": "docs"
        },
        {
          "title": "DeepMind's protein-folding AI solved a 50-year puzzle",
          "url": "https://fortune.com/2020/11/30/deepmind-solved-protein-folding-alphafold/",
          "type": "blog"
        }
      ]
    },
    {
      "id": "dalle-1-2021",
      "title": "DALL-E - text-till-bild-generering",
      "date": "2021-01-05",
      "dateDisplay": "Januari 2021",
      "category": "models",
      "company": "openai",
      "importance": 9,
      "shortDesc": "AI skapar bilder fr√•n textbeskrivningar",
      "detailedDesc": "DALL-E (en kombination av Salvador Dal√≠ och WALL-E) demonstrerade f√∂rm√•gan att generera kreativa bilder fr√•n textbeskrivningar. Detta √∂ppnade d√∂rren f√∂r AI-konst.",
      "significance": "Visade att AI kan vara kreativ och f√∂rst√• abstrakta koncept tillr√§ckligt f√∂r att visualisera dem.",
      "capabilityArea": "multimodal",
      "beforeAfter": {
        "before": "AI kunde inte skapa meningsfulla bilder fr√•n text",
        "after": "AI kan generera kreativa, komplexa bilder fr√•n beskrivningar"
      },
      "keyPeople": ["Aditya Ramesh"],
      "tags": ["multimodal", "bildgenerering", "kreativitet"],
      "sources": [
        {
          "title": "AI history timeline",
          "url": "https://en.wikipedia.org/wiki/History_of_artificial_intelligence",
          "type": "reference"
        }
      ]
    },
    {
      "id": "clip-2021",
      "title": "CLIP - vision-spr√•kbrygga",
      "date": "2021-01-05",
      "dateDisplay": "Januari 2021",
      "category": "models",
      "company": "openai",
      "importance": 8,
      "shortDesc": "AI f√∂rst√•r relationen mellan bilder och text",
      "detailedDesc": "CLIP (Contrastive Language-Image Pre-training) l√§rde sig kopplingen mellan bilder och text genom att tr√§nas p√• miljontals bild-text-par fr√•n internet.",
      "significance": "CLIP m√∂jliggjorde zero-shot bildklassificering och blev fundamentet f√∂r m√•nga multimodala modeller.",
      "capabilityArea": "multimodal",
      "keyPeople": ["Alec Radford", "Ilya Sutskever"],
      "tags": ["multimodal", "vision-spr√•k", "zero-shot"],
      "sources": [
        {
          "title": "AI history timeline",
          "url": "https://en.wikipedia.org/wiki/History_of_artificial_intelligence",
          "type": "reference"
        }
      ]
    },
    {
      "id": "codex-2021",
      "title": "Codex och GitHub Copilot",
      "date": "2021-06-29",
      "dateDisplay": "Juni 2021",
      "category": "products",
      "company": "openai",
      "importance": 9,
      "shortDesc": "AI-assisterad kodning blir verklighet",
      "detailedDesc": "OpenAI:s Codex, tr√§nad p√• kod fr√•n GitHub, kunde skriva funktionell kod fr√•n naturlig spr√•kbeskrivning. GitHub Copilot gjorde detta tillg√§ngligt f√∂r miljontals utvecklare.",
      "significance": "F√∂rsta stora praktiska till√§mpningen av stora spr√•kmodeller. F√∂r√§ndrade hur utvecklare arbetar och startade AI-kodningsrevolutionen.",
      "capabilityArea": "coding",
      "beforeAfter": {
        "before": "Utvecklare skrev all kod manuellt",
        "after": "AI kan generera, komplettera och f√∂rklara kod"
      },
      "metrics": [
        {"name": "HumanEval pass@1", "value": "29%", "comparison": "2021 baseline"}
      ],
      "keyPeople": ["Chen Mark", "Greg Brockman"],
      "tags": ["kodning", "Copilot", "utvecklarverktyg"],
      "sources": [
        {
          "title": "AI timeline history",
          "url": "https://en.wikipedia.org/wiki/History_of_artificial_intelligence",
          "type": "reference"
        }
      ]
    },
    {
      "id": "stable-diffusion-2022",
      "title": "Stable Diffusion blir √∂ppen k√§llkod",
      "date": "2022-08-22",
      "dateDisplay": "Augusti 2022",
      "category": "models",
      "company": "stability",
      "importance": 8,
      "shortDesc": "Demokratiserad AI-konstgenerering",
      "detailedDesc": "Stability AI sl√§ppte Stable Diffusion som √∂ppen k√§llkod, vilket gjorde h√∂gkvalitativ bildgenerering tillg√§nglig f√∂r alla. Detta startade en explosion av kreativa AI-applikationer.",
      "significance": "Demokratiserade AI-konst och visade kraften i √∂ppen k√§llkod f√∂r AI. Miljontals m√§nniskor kunde nu experimentera med AI-bildgenerering.",
      "capabilityArea": "multimodal",
      "keyPeople": ["Emad Mostaque"],
      "tags": ["bildgenerering", "√∂ppen k√§llkod", "diffusion"],
      "sources": [
        {
          "title": "AI history timeline",
          "url": "https://en.wikipedia.org/wiki/History_of_artificial_intelligence",
          "type": "reference"
        }
      ]
    },
    {
      "id": "chatgpt-2022",
      "title": "ChatGPT lanseras",
      "date": "2022-11-30",
      "dateDisplay": "30 November 2022",
      "category": "products",
      "company": "openai",
      "importance": 10,
      "shortDesc": "100 miljoner anv√§ndare p√• 2 m√•nader - allm√§nhetens AI-uppvaknande",
      "detailedDesc": "ChatGPT lanserades och blev den snabbast v√§xande konsumentapplikationen i historien. 100 miljoner anv√§ndare p√• tv√• m√•nader - j√§mf√∂rt med 9 m√•nader f√∂r TikTok och 2.5 √•r f√∂r Instagram.",
      "significance": "√ñgonblicket d√• AI blev mainstream. ChatGPT gjorde kraftfull AI tillg√§nglig f√∂r alla och startade den globala AI-revolutionen.",
      "capabilityArea": "language",
      "beforeAfter": {
        "before": "AI var n√•got f√∂r forskare och tech-f√∂retag",
        "after": "Hundratals miljoner m√§nniskor anv√§nder AI dagligen"
      },
      "metrics": [
        {"name": "Anv√§ndare", "value": "100M p√• 2 m√•nader", "comparison": "Snabbaste tillv√§xten n√•gonsin"}
      ],
      "keyPeople": ["Sam Altman", "Greg Brockman"],
      "tags": ["ChatGPT", "genombrott", "mainstream"],
      "sources": [
        {
          "title": "ChatGPT - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/ChatGPT",
          "type": "reference"
        },
        {
          "title": "ChatGPT Statistics",
          "url": "https://www.notta.ai/en/blog/chatgpt-statistics",
          "type": "blog"
        }
      ]
    },
    {
      "id": "gpt-4-2023",
      "title": "GPT-4 - multimodal och klarar advokatexamen",
      "date": "2023-03-14",
      "dateDisplay": "14 Mars 2023",
      "category": "models",
      "company": "openai",
      "importance": 10,
      "shortDesc": "Multimodal AI med professionell kompetensniv√•",
      "detailedDesc": "GPT-4 introducerade multimodala f√∂rm√•gor (text och bild) och visade professionell kompetensniv√• genom att klara advokatexamen i 90:e percentilen. Kvalitetshoppet fr√•n GPT-3.5 var dramatiskt.",
      "significance": "Visade att AI kan prestera p√• professionell niv√• i komplexa uppgifter. Multimodala f√∂rm√•gor √∂ppnade nya anv√§ndningsomr√•den.",
      "capabilityArea": "multimodal",
      "beforeAfter": {
        "before": "AI var begr√§nsad till grundl√§ggande uppgifter",
        "after": "AI kan prestera p√• niv√• med m√§nskliga experter"
      },
      "metrics": [
        {"name": "Advokatexamen", "value": "90:e percentilen", "comparison": "vs 10:e f√∂r GPT-3.5"}
      ],
      "keyPeople": ["Sam Altman", "Ilya Sutskever"],
      "tags": ["GPT-4", "multimodal", "benchmark"],
      "sources": [
        {
          "title": "ChatGPT - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/ChatGPT",
          "type": "reference"
        }
      ]
    },
    {
      "id": "claude-1-2023",
      "title": "Claude fr√•n Anthropic",
      "date": "2023-03-14",
      "dateDisplay": "Mars 2023",
      "category": "models",
      "company": "anthropic",
      "importance": 8,
      "shortDesc": "Constitutional AI och 100K kontext",
      "detailedDesc": "Anthropic lanserade Claude med Constitutional AI f√∂r att g√∂ra modellen mer hj√§lpsam, harml√∂s och √§rlig. 100K token-kontext var banbrytande.",
      "significance": "Introducerade viktiga s√§kerhetskoncept och visade att l√§ngre kontext m√∂jligg√∂r nya anv√§ndningsfall.",
      "capabilityArea": "language",
      "beforeAfter": {
        "before": "Modeller var begr√§nsade till ~4K tokens kontext",
        "after": "Claude kunde hantera hela b√∂cker i en konversation"
      },
      "metrics": [
        {"name": "Kontext", "value": "100K tokens", "comparison": "vs 4K f√∂r GPT-3.5"}
      ],
      "keyPeople": ["Dario Amodei", "Daniela Amodei"],
      "tags": ["Claude", "s√§kerhet", "constitutional AI"],
      "sources": [
        {
          "title": "Claude (language model) - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/Claude_(language_model)",
          "type": "reference"
        }
      ]
    },
    {
      "id": "midjourney-v5-2023",
      "title": "Midjourney V5 - fotorealistisk AI-konst",
      "date": "2023-03-15",
      "dateDisplay": "Mars 2023",
      "category": "products",
      "company": "midjourney",
      "importance": 7,
      "shortDesc": "AI-genererade bilder blir o√•tskiljliga fr√•n foton",
      "detailedDesc": "Midjourney V5 n√•dde en niv√• av fotorealism d√§r AI-genererade bilder blev n√§stan o√•tskiljliga fr√•n riktiga fotografier.",
      "significance": "Visade att AI-konst n√•r professionell kvalitet och v√§ckte fr√•gor om autenticitet och upphovsr√§tt.",
      "capabilityArea": "multimodal",
      "keyPeople": ["David Holz"],
      "tags": ["bildgenerering", "konst", "fotorealism"],
      "sources": [
        {
          "title": "Tracing the History of Anthropic's Claude",
          "url": "https://medium.com/@sebastian.lambright/tracing-the-history-of-anthropics-claude-05f2a363dc94",
          "type": "blog"
        }
      ]
    },
    {
      "id": "autogpt-2023",
      "title": "Auto-GPT - tidiga autonoma agenter",
      "date": "2023-03-30",
      "dateDisplay": "Mars 2023",
      "category": "tools",
      "importance": 7,
      "shortDesc": "F√∂rsta f√∂rs√∂ken med sj√§lvst√§ndiga AI-agenter",
      "detailedDesc": "Auto-GPT visade konceptet med autonoma AI-agenter som kan planera och utf√∂ra fler-stegs uppgifter sj√§lvst√§ndigt.",
      "significance": "Startade diskussionen och utvecklingen av agentic AI - system som kan arbeta sj√§lvst√§ndigt mot m√•l.",
      "capabilityArea": "agentic",
      "beforeAfter": {
        "before": "AI beh√∂vde guidning f√∂r varje steg",
        "after": "AI b√∂rjade experimentera med sj√§lvst√§ndig uppgiftsl√∂sning"
      },
      "tags": ["agenter", "autonomi", "planering"],
      "sources": [
        {
          "title": "AI timeline",
          "url": "https://en.wikipedia.org/wiki/History_of_artificial_intelligence",
          "type": "reference"
        }
      ]
    },
    {
      "id": "gpt-4-vision-2023",
      "title": "GPT-4 Vision",
      "date": "2023-09-25",
      "dateDisplay": "September 2023",
      "category": "models",
      "company": "openai",
      "importance": 8,
      "shortDesc": "GPT-4 kan se och f√∂rst√• bilder",
      "detailedDesc": "GPT-4 med vision (GPT-4V) blev tillg√§nglig, vilket g√∂r att modellen kan analysera och resonera kring bilder, diagram, sk√§rmdumpar och mer.",
      "significance": "Multimodal f√∂rst√•else blev praktiskt anv√§ndbar, vilket √∂ppnade f√∂r nya till√§mpningar inom utbildning, tillg√§nglighet och analys.",
      "capabilityArea": "multimodal",
      "tags": ["vision", "multimodal", "GPT-4"],
      "sources": [
        {
          "title": "ChatGPT - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/ChatGPT",
          "type": "reference"
        }
      ]
    },
    {
      "id": "claude-2.1-2023",
      "title": "Claude 2.1 med 200K kontext",
      "date": "2023-11-21",
      "dateDisplay": "November 2023",
      "category": "models",
      "company": "anthropic",
      "importance": 7,
      "shortDesc": "L√•ng dokumentanalys blir m√∂jlig",
      "detailedDesc": "Claude 2.1 ut√∂kade kontextf√∂nstret till 200K tokens, vilket motsvarar cirka 150 000 ord eller 500 sidor. Detta m√∂jliggjorde analys av mycket l√•nga dokument.",
      "significance": "Visade v√§gen mot √§nnu l√§ngre kontext och m√∂jliggjorde helt nya anv√§ndningsfall f√∂r dokumentanalys.",
      "capabilityArea": "language",
      "metrics": [
        {"name": "Kontext", "value": "200K tokens", "comparison": "~500 sidor text"}
      ],
      "tags": ["Claude", "l√•ngt kontext", "dokumentanalys"],
      "sources": [
        {
          "title": "Claude - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/Claude_(language_model)",
          "type": "reference"
        }
      ]
    },
    {
      "id": "gemini-pro-2023",
      "title": "Gemini Pro fr√•n Google",
      "date": "2023-12-06",
      "dateDisplay": "December 2023",
      "category": "models",
      "company": "google",
      "importance": 8,
      "shortDesc": "Googles multimodala svar p√• GPT-4",
      "detailedDesc": "Google lanserade Gemini-familjen med Pro som mittenniv√•, designad fr√•n grunden f√∂r multimodal f√∂rst√•else.",
      "significance": "Google blev en seri√∂s konkurrent i frontier AI-t√§vlingen, vilket accelererade utvecklingen.",
      "capabilityArea": "multimodal",
      "keyPeople": ["Demis Hassabis", "Sundar Pichai"],
      "tags": ["Gemini", "multimodal", "Google"],
      "sources": [
        {
          "title": "Claude timeline history",
          "url": "https://medium.com/@sebastian.lambright/tracing-the-history-of-anthropics-claude-05f2a363dc94",
          "type": "blog"
        }
      ]
    },
    {
      "id": "mixtral-2023",
      "title": "Mixtral 8x7B - √∂ppen MoE",
      "date": "2023-12-11",
      "dateDisplay": "December 2023",
      "category": "models",
      "company": "mistral",
      "importance": 7,
      "shortDesc": "√ñppen k√§llkod konkurrerar med st√§ngda modeller",
      "detailedDesc": "Mistral AI:s Mixtral 8x7B anv√§nder Mixture of Experts-arkitektur och visade att √∂ppna modeller kan konkurrera med st√§ngda frontier-modeller.",
      "significance": "Bevisade att √∂ppen k√§llkod h√•ller j√§mna steg med st√§ngda modeller, vilket demokratiserar tillg√•ngen till kraftfull AI.",
      "capabilityArea": "language",
      "tags": ["√∂ppen k√§llkod", "MoE", "Mistral"],
      "sources": [
        {
          "title": "Claude history",
          "url": "https://medium.com/@sebastian.lambright/tracing-the-history-of-anthropics-claude-05f2a363dc94",
          "type": "blog"
        }
      ]
    },
    {
      "id": "gemini-1.5-2024",
      "title": "Gemini 1.5 Pro med 1M tokens",
      "date": "2024-02-15",
      "dateDisplay": "Februari 2024",
      "category": "models",
      "company": "google",
      "importance": 9,
      "shortDesc": "Massivt kontextgenombrott - 1 miljon tokens",
      "detailedDesc": "Gemini 1.5 Pro introducerade ett 1 miljoner token kontextf√∂nster, vilket m√∂jligg√∂r analys av timsl√•ng video, hundratals tusen rader kod, eller hundratals dokument samtidigt.",
      "significance": "Ett kvantspr√•ng i kontextl√§ngd som m√∂jliggjorde helt nya anv√§ndningsfall och visade skalbarhet i arkitekturen.",
      "capabilityArea": "multimodal",
      "beforeAfter": {
        "before": "Kontext var begr√§nsad till ~200K tokens",
        "after": "1M tokens m√∂jligg√∂r analys av massiva datam√§ngder"
      },
      "metrics": [
        {"name": "Kontext", "value": "1M tokens", "comparison": "vs 200K f√∂r Claude 2.1"}
      ],
      "tags": ["Gemini", "kontext", "genombrott"],
      "sources": [
        {
          "title": "Claude timeline",
          "url": "https://medium.com/@sebastian.lambright/tracing-the-history-of-anthropics-claude-05f2a363dc94",
          "type": "blog"
        }
      ]
    },
    {
      "id": "claude-3-2024",
      "title": "Claude 3-familjen",
      "date": "2024-03-04",
      "dateDisplay": "4 Mars 2024",
      "category": "models",
      "company": "anthropic",
      "importance": 9,
      "shortDesc": "Haiku, Sonnet och Opus - f√∂rsta g√•ngen Anthropic sl√•r GPT-4",
      "detailedDesc": "Claude 3-familjen (Haiku, Sonnet, Opus) lanserades med Opus som √∂vertr√§ffade GPT-4 p√• de flesta benchmarks. Tre modellstorlekar f√∂r olika anv√§ndningsfall.",
      "significance": "Visade att konkurrensen driver innovation. Opus blev den f√∂rsta modellen att konsekvent sl√• GPT-4.",
      "capabilityArea": "multimodal",
      "beforeAfter": {
        "before": "GPT-4 var ohotad i toppen",
        "after": "Opus visade att GPT-4 kunde √∂vertr√§ffas"
      },
      "metrics": [
        {"name": "MMLU", "value": "86.8%", "comparison": "vs 86.4% f√∂r GPT-4"}
      ],
      "keyPeople": ["Dario Amodei"],
      "tags": ["Claude", "benchmark", "konkurrens"],
      "sources": [
        {
          "title": "Anthropic: Claude 3 Family",
          "url": "https://www.anthropic.com/news/claude-3-family",
          "type": "announcement"
        },
        {
          "title": "Claude - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/Claude_(language_model)",
          "type": "reference"
        }
      ]
    },
    {
      "id": "claude-3.5-sonnet-2024",
      "title": "Claude 3.5 Sonnet med Artifacts",
      "date": "2024-06-20",
      "dateDisplay": "20 Juni 2024",
      "category": "models",
      "company": "anthropic",
      "importance": 9,
      "shortDesc": "Kodningsexcellens och interaktiva artifacts",
      "detailedDesc": "Claude 3.5 Sonnet √∂vertr√§ffade Opus trots att vara mindre och introducerade Artifacts - f√∂rm√•gan att skapa interaktiv kod i separata f√∂nster.",
      "significance": "Visade att intelligens per parameter f√∂rb√§ttras snabbt. Artifacts f√∂r√§ndrade hur anv√§ndare interagerar med AI-genererad kod.",
      "capabilityArea": "coding",
      "beforeAfter": {
        "before": "AI-genererad kod var statisk text",
        "after": "AI skapar interaktiva, k√∂rbara artifacts i realtid"
      },
      "metrics": [
        {"name": "Kodningsbenchmarks", "value": "Topp 3", "comparison": "√ñvertr√§ffar st√∂rre Opus"}
      ],
      "tags": ["Claude", "kodning", "artifacts"],
      "sources": [
        {
          "title": "Introducing Claude 3.5 Sonnet",
          "url": "https://www.anthropic.com/news/claude-3-5-sonnet",
          "type": "announcement"
        }
      ]
    },
    {
      "id": "openai-o1-2024",
      "title": "OpenAI o1 - reasoning-modell",
      "date": "2024-09-12",
      "dateDisplay": "12 September 2024",
      "category": "models",
      "company": "openai",
      "importance": 10,
      "shortDesc": "Chain-of-thought reasoning - AI som t√§nker steg f√∂r steg",
      "detailedDesc": "OpenAI o1 introducerade explicit resonemang genom 'chain of thought'. Modellen 't√§nker' f√∂re den svarar, vilket g√∂r den mycket b√§ttre p√• matematik, programmering och komplexa problem.",
      "significance": "Ett paradigmskifte fr√•n snabba svar till genomt√§nkt resonemang. Visar att l√§ngre 'tanketid' ger kvalitativt b√§ttre resultat.",
      "capabilityArea": "reasoning",
      "beforeAfter": {
        "before": "Modeller svarade omedelbart utan synligt resonemang",
        "after": "o1 visar tankekedjor och n√•r expert-niv√• i matematik"
      },
      "metrics": [
        {"name": "AIME matematik", "value": "74% (13.9/15)", "comparison": "Topp 500 nationellt i USA"},
        {"name": "Codeforces", "value": "89:e percentilen", "comparison": "vs 11:e f√∂r GPT-4o"}
      ],
      "keyPeople": ["Jakub Pachocki", "Sam Altman"],
      "tags": ["reasoning", "o1", "chain-of-thought"],
      "sources": [
        {
          "title": "Learning to reason with LLMs - OpenAI",
          "url": "https://openai.com/index/learning-to-reason-with-llms/",
          "type": "announcement"
        },
        {
          "title": "OpenAI o1 - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/OpenAI_o1",
          "type": "reference"
        }
      ]
    },
    {
      "id": "claude-computer-use-2024",
      "title": "Claude 3.5 Sonnet med Computer Use",
      "date": "2024-10-22",
      "dateDisplay": "22 Oktober 2024",
      "category": "products",
      "company": "anthropic",
      "importance": 9,
      "shortDesc": "AI kan kontrollera datorer - flytta musen, klicka, skriva",
      "detailedDesc": "Claude 3.5 Sonnet fick f√∂rm√•gan att kontrollera datorer genom att se sk√§rmen och anv√§nda mus och tangentbord. Detta √∂ppnade f√∂r automation av n√§stan vilken datoruppgift som helst.",
      "significance": "Ett stort steg mot generell AI-assistans. Visade att AI kan interagera med mjukvara designad f√∂r m√§nniskor.",
      "capabilityArea": "agentic",
      "beforeAfter": {
        "before": "AI var begr√§nsad till textgr√§nssnitt och API:er",
        "after": "AI kan anv√§nda vilken mjukvara som helst genom GUI"
      },
      "tags": ["computer use", "automation", "agentic"],
      "sources": [
        {
          "title": "Claude - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/Claude_(language_model)",
          "type": "reference"
        }
      ]
    },
    {
      "id": "mcp-2024",
      "title": "Model Context Protocol (MCP)",
      "date": "2024-11-25",
      "dateDisplay": "25 November 2024",
      "category": "tools",
      "company": "anthropic",
      "importance": 8,
      "shortDesc": "√ñppen standard f√∂r AI-verktygsintegration",
      "detailedDesc": "Anthropic introducerade Model Context Protocol (MCP) - en √∂ppen standard f√∂r att koppla AI-assistenter till datasystem. L√∂ser 'M√óN-problemet' d√§r varje modell annars beh√∂ver separata kopplingar till varje verktyg.",
      "significance": "Standardisering accelererar ekosystemet. MCP fick snabbt st√∂d fr√•n OpenAI, Microsoft, Cloudflare och Cursor.",
      "capabilityArea": "integration",
      "beforeAfter": {
        "before": "Varje AI-verktyg beh√∂vde egna integrations f√∂r varje datak√§lla",
        "after": "En standard g√∂r integrationer √•teranv√§ndbara och skalbar"
      },
      "keyPeople": ["David Soria Parra", "Justin Spahr-Summers"],
      "tags": ["standard", "integration", "protokoll"],
      "sources": [
        {
          "title": "Introducing the Model Context Protocol - Anthropic",
          "url": "https://www.anthropic.com/news/model-context-protocol",
          "type": "announcement"
        },
        {
          "title": "Model Context Protocol - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/Model_Context_Protocol",
          "type": "reference"
        }
      ]
    },
    {
      "id": "openai-o1-full-2024",
      "title": "OpenAI o1 - full release",
      "date": "2024-12-05",
      "dateDisplay": "5 December 2024",
      "category": "models",
      "company": "openai",
      "importance": 9,
      "shortDesc": "Production reasoning-modell tillg√§nglig f√∂r alla",
      "detailedDesc": "Den fullst√§ndiga versionen av o1 sl√§pptes f√∂r produktion efter preview-fasen. F√∂rb√§ttringar inkluderar b√§ttre multimodal f√∂rst√•else och snabbare inferens.",
      "significance": "Reasoning-modeller blir mainstream och tillg√§ngliga f√∂r praktiska till√§mpningar.",
      "capabilityArea": "reasoning",
      "tags": ["o1", "production", "reasoning"],
      "sources": [
        {
          "title": "OpenAI o1 System Card",
          "url": "https://cdn.openai.com/o1-system-card-20241205.pdf",
          "type": "docs"
        }
      ]
    },
    {
      "id": "gemini-2.0-2024",
      "title": "Gemini 2.0 Flash",
      "date": "2024-12-11",
      "dateDisplay": "11 December 2024",
      "category": "models",
      "company": "google",
      "importance": 8,
      "shortDesc": "Agentic AI med native verktygsanv√§ndning",
      "detailedDesc": "Gemini 2.0 Flash introducerades som Googles f√∂rsta modell byggd fr√•n grunden f√∂r agentic anv√§ndning, med native st√∂d f√∂r verktygsanv√§ndning och multimodala output.",
      "significance": "Visar tydligt skiftet mot agentic AI d√§r modeller inte bara svarar utan agerar och anv√§nder verktyg.",
      "capabilityArea": "agentic",
      "metrics": [
        {"name": "MATH-500", "value": "78.3%", "comparison": "vs 64.1% f√∂r standard Flash"}
      ],
      "tags": ["Gemini", "agentic", "verktyg"],
      "sources": [
        {
          "title": "OpenAI o1 article (Gemini comparison)",
          "url": "https://simonwillison.net/2024/Sep/12/openai-o1/",
          "type": "blog"
        }
      ]
    },
    {
      "id": "claude-sonnet-4.5-2024",
      "title": "Claude Sonnet 4.5",
      "date": "2024-12-20",
      "dateDisplay": "December 2024",
      "category": "models",
      "company": "anthropic",
      "importance": 9,
      "shortDesc": "Ny SOTA across benchmarks",
      "detailedDesc": "Claude Sonnet 4.5 satte nya rekord √∂ver flera benchmarks och etablerade Anthropic som ledande inom frontier AI.",
      "significance": "Fortsatt snabb f√∂rb√§ttring visar att vi √§r l√•ngt fr√•n plat√•n. Konkurrensen driver constant innovation.",
      "capabilityArea": "multimodal",
      "tags": ["Claude", "SOTA", "benchmark"],
      "sources": [
        {
          "title": "Anthropic news updates",
          "url": "https://www.anthropic.com/news",
          "type": "announcement"
        }
      ]
    },
    {
      "id": "claude-code-2024",
      "title": "Claude Code",
      "date": "2024-12-15",
      "dateDisplay": "December 2024",
      "category": "tools",
      "company": "anthropic",
      "importance": 8,
      "shortDesc": "Officiell Anthropic kodningsagent f√∂r terminal & IDE",
      "detailedDesc": "Claude Code lanserades som Anthropics kommandoradsverktyg f√∂r agentic kodning, med integrationer f√∂r VS Code, Cursor, Windsurf och JetBrains.",
      "significance": "Kodningsagenter fr√•n frontier labs visar hur AI blir en naturlig del av utvecklingsfl√∂det.",
      "capabilityArea": "coding",
      "tags": ["kodning", "agent", "CLI"],
      "sources": [
        {
          "title": "Claude Code - Anthropic",
          "url": "https://www.anthropic.com/claude-code",
          "type": "docs"
        }
      ]
    },
    {
      "id": "arc-agi-breakthrough-2024",
      "title": "ARC-AGI genombrott: 5% ‚Üí 76%",
      "date": "2024-12-20",
      "dateDisplay": "December 2024",
      "category": "benchmarks",
      "company": "openai",
      "importance": 10,
      "shortDesc": "OpenAI o3 g√∂r dramatiskt hopp p√• AGI-benchmark",
      "detailedDesc": "ARC-AGI benchmark tog 4 √•r att g√• fr√•n 0% (GPT-3, 2020) till 5% (GPT-4o, tidig 2024). OpenAI:s o3 n√•dde 75.7% (low-compute) till 87.5% (high-compute) i slutet av 2024 - ett enormt hopp.",
      "significance": "Det st√∂rsta steghoppet i AI-f√∂rm√•ga p√• ett enda √•r. Visar att novel task adaptation - en k√§rnkomponent i AGI - f√∂rb√§ttras dramatiskt.",
      "capabilityArea": "reasoning",
      "beforeAfter": {
        "before": "AI kunde inte generalisera till nya typer av uppgifter",
        "after": "o3 visar signifikant f√∂rm√•ga till abstrakt resonemang"
      },
      "metrics": [
        {"name": "ARC-AGI score", "value": "75.7%", "comparison": "vs 5% f√∂r GPT-4o tidig 2024"},
        {"name": "√Örlig f√∂rb√§ttring", "value": "1420% √∂kning", "comparison": "Fr√•n 5% till 76% p√• <1 √•r"}
      ],
      "keyPeople": ["Fran√ßois Chollet"],
      "tags": ["AGI", "benchmark", "resonemang"],
      "sources": [
        {
          "title": "OpenAI o3 Breakthrough on ARC-AGI",
          "url": "https://arcprize.org/blog/oai-o3-pub-breakthrough",
          "type": "announcement"
        },
        {
          "title": "ARC Prize 2024 Technical Report",
          "url": "https://arxiv.org/html/2412.04604v2",
          "type": "paper"
        }
      ]
    },
    {
      "id": "cursor-ide-2024",
      "title": "Cursor IDE - AI pair programming",
      "date": "2024-06-01",
      "dateDisplay": "2024",
      "category": "tools",
      "company": "cursor",
      "importance": 7,
      "shortDesc": "AI-native kodredigerare f√∂r√§ndrar utveckling",
      "detailedDesc": "Cursor IDE blev popul√§rt som en AI-native fork av VS Code med djup integration av spr√•kmodeller f√∂r kodgenerering, refactoring och f√∂rklaring.",
      "significance": "Visar hur specialiserade verktyg kan g√∂ra AI mer anv√§ndbar √§n generella chattgr√§nssnitt.",
      "capabilityArea": "coding",
      "tags": ["IDE", "kodning", "verktyg"],
      "sources": [
        {
          "title": "Best AI Coding IDE 2025 Comparison",
          "url": "https://www.humai.blog/best-ai-coding-ide-2025-cursor-vs-antigravity-vs-claude-code-vs-windsurf-the-complete-comparison/",
          "type": "blog"
        }
      ]
    },
    {
      "id": "windsurf-2024",
      "title": "Windsurf Editor (Codeium)",
      "date": "2024-11-01",
      "dateDisplay": "November 2024",
      "category": "tools",
      "company": "codeium",
      "importance": 7,
      "shortDesc": "Multi-fil autonom redigering med Cascade",
      "detailedDesc": "Codeiums Windsurf IDE integrerar Claude och egna modeller i Cascade-systemet f√∂r fl√∂desbaserad AI-kodning. Hundratusentals anv√§ndare inom veckor.",
      "significance": "Snabb adoption visar hungren efter b√§ttre AI-kodningsverktyg. Claude-integration visar v√§rdet av specialiserade modeller.",
      "capabilityArea": "coding",
      "tags": ["IDE", "kodning", "Cascade"],
      "sources": [
        {
          "title": "Codeium's Windsurf with Claude Integration",
          "url": "https://analyticsindiamag.com/ai-news-updates/codeiums-windsurf-takes-coding-to-the-next-level-with-anthropic-claude-integration/",
          "type": "blog"
        }
      ]
    },
    {
      "id": "eu-ai-act-2025",
      "title": "EU AI Act - F√∂rsta stora regulatory milestone",
      "date": "2025-02-02",
      "dateDisplay": "2 Februari 2025",
      "category": "companies",
      "importance": 9,
      "shortDesc": "EU:s AI-lag b√∂rjar till√§mpas - f√∂rbud mot h√∂griskanv√§ndningar",
      "detailedDesc": "Den 2 februari 2025 b√∂rjade EU:s AI Act formellt till√§mpas √∂ver alla 27 medlemsl√§nder. F√∂rbud mot 'oacceptabel risk' AI-praxis blev juridiskt bindande, inklusive mass√∂vervakning och social scoring.",
      "significance": "F√∂rsta stora globala AI-regleringsmilstolpen. S√§tter precedent f√∂r ansvarsfull AI-utveckling v√§rlden √∂ver och introducerar b√∂ter upp till ‚Ç¨35M eller 7% av global oms√§ttning.",
      "capabilityArea": "regulation",
      "beforeAfter": {
        "before": "AI-utveckling var oreglerad i Europa",
        "after": "Juridiskt ramverk med kraftfulla sanktioner p√• plats"
      },
      "metrics": [
        {"name": "Maximal b√∂t", "value": "‚Ç¨35M eller 7% oms√§ttning", "comparison": "H√∂gsta sanktioner n√•gonsin f√∂r AI"}
      ],
      "keyPeople": ["Ursula von der Leyen"],
      "tags": ["regulering", "EU", "policy"],
      "sources": [
        {
          "title": "EU Artificial Intelligence Act Implementation Timeline",
          "url": "https://artificialintelligenceact.eu/implementation-timeline/",
          "type": "docs"
        },
        {
          "title": "Initial Prohibitions Under EU AI Act Take Effect",
          "url": "https://www.quinnemanuel.com/the-firm/publications/initial-prohibitions-under-eu-ai-act-take-effect/",
          "type": "announcement"
        }
      ]
    },
    {
      "id": "openai-o3-2025",
      "title": "OpenAI o3 - Full release med ARC-AGI genombrott",
      "date": "2025-04-15",
      "dateDisplay": "April 2025",
      "category": "models",
      "company": "openai",
      "importance": 10,
      "shortDesc": "87.5% p√• ARC-AGI - dramatiskt hopp i abstrakta resonemangf√∂rm√•ga",
      "detailedDesc": "OpenAI sl√§ppte o3 fullt i april 2025 efter att ha annonserat det i december 2024. Modellen uppn√•dde 87.5% p√• ARC-AGI med high-compute konfiguration, j√§mf√∂rt med 5% f√∂r GPT-4o - ett av de st√∂rsta spr√•ngen i AI-f√∂rm√•ga n√•gonsin.",
      "significance": "Visar dramatisk f√∂rb√§ttring i novel task adaptation - en k√§rnkomponent i AGI. Fr√•n 5% till 87.5% representerar ett paradigmskifte i abstrakt resonemang.",
      "capabilityArea": "reasoning",
      "beforeAfter": {
        "before": "AI stagnerade p√• ~5% ARC-AGI i flera √•r",
        "after": "o3 n√•r 87.5%, n√§rmar sig m√§nsklig prestanda (77%)"
      },
      "metrics": [
        {"name": "ARC-AGI score", "value": "87.5%", "comparison": "vs 5% f√∂r GPT-4o"},
        {"name": "F√∂rb√§ttring", "value": "1650%", "comparison": "17.5√ó b√§ttre √§n GPT-4o"}
      ],
      "keyPeople": ["Sam Altman"],
      "tags": ["reasoning", "benchmark", "AGI"],
      "sources": [
        {
          "title": "OpenAI o3 Breakthrough on ARC-AGI",
          "url": "https://arcprize.org/blog/oai-o3-pub-breakthrough",
          "type": "announcement"
        },
        {
          "title": "OpenAI's o3 shows remarkable progress on ARC-AGI",
          "url": "https://venturebeat.com/ai/openais-o3-shows-remarkable-progress-on-arc-agi-sparking-debate-on-ai-reasoning",
          "type": "blog"
        }
      ],
      "relatedMilestones": ["arc-agi-breakthrough-2024"]
    },
    {
      "id": "gemini-3-2025",
      "title": "Gemini 3 - SOTA p√• flera benchmarks",
      "date": "2025-11-18",
      "dateDisplay": "18 November 2025",
      "category": "models",
      "company": "google",
      "importance": 10,
      "shortDesc": "Google lanserar Gemini 3 Pro - 100% AIME, h√∂gsta Humanity's Last Exam",
      "detailedDesc": "Google sl√§ppte Gemini 3 i november 2025 med dramatiska f√∂rb√§ttringar p√• matematisk och vetenskaplig reasoning. Uppn√•dde perfekt 100% p√• AIME 2025, 91.9% p√• GPQA Diamond, och h√∂gsta po√§ng n√•gonsin p√• Humanity's Last Exam (37.4). P√• MathArena Apex f√∂rb√§ttrades prestandan 46√ó j√§mf√∂rt med Gemini 2.5.",
      "significance": "Markerade Googles √•terkomst till frontlinjen av AI-utveckling. Dramatiska hopp p√• flera benchmarks visar kvalitativa genombrott i reasoning-f√∂rm√•ga, s√§rskilt f√∂r komplexa multi-step problem.",
      "capabilityArea": "multimodal",
      "beforeAfter": {
        "before": "Gemini 2.5 Pro: 0.5% MathArena Apex, 4.9% ARC-AGI-2",
        "after": "Gemini 3 Pro: 23.4% MathArena (46√ó), 31.1% ARC-AGI-2 (6√ó)"
      },
      "metrics": [
        {"name": "AIME 2025", "value": "100%", "comparison": "Perfekt po√§ng p√• matematik"},
        {"name": "GPQA Diamond", "value": "91.9%", "comparison": "vs 86.4% f√∂r Gemini 2.5"},
        {"name": "MathArena Apex", "value": "23.4%", "comparison": "46√ó f√∂rb√§ttring (0.5% ‚Üí 23.4%)"},
        {"name": "Humanity's Last Exam", "value": "37.4", "comparison": "H√∂gsta po√§ng n√•gonsin"}
      ],
      "keyPeople": ["Demis Hassabis", "Sundar Pichai"],
      "tags": ["Gemini", "multimodal", "SOTA", "matematik"],
      "sources": [
        {
          "title": "Gemini 3 Pro Model Card (November 2025)",
          "url": "https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf",
          "type": "docs"
        },
        {
          "title": "Google unveils Gemini 3 claiming lead in benchmarks",
          "url": "https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and",
          "type": "announcement"
        },
        {
          "title": "Gemini 3 Benchmarks Explained",
          "url": "https://www.vellum.ai/blog/google-gemini-3-benchmarks",
          "type": "blog"
        }
      ]
    }
  ],

  "accelerationMetrics": {
    "eventsPerPeriod": [
      {
        "period": "1950-2010",
        "years": 60,
        "count": 8,
        "avgMonthsApart": 90,
        "description": "Grundl√§ggande forskning och tidiga genombrott"
      },
      {
        "period": "2011-2016",
        "years": 6,
        "count": 4,
        "avgMonthsApart": 18,
        "description": "Deep learning b√∂rjar visa potential"
      },
      {
        "period": "2017-2020",
        "years": 4,
        "count": 10,
        "avgMonthsApart": 4.8,
        "description": "Transformer-revolution och skalning"
      },
      {
        "period": "2021-2023",
        "years": 3,
        "count": 13,
        "avgMonthsApart": 2.8,
        "description": "Publika AI-appar och mainstream-adoption"
      },
      {
        "period": "2024-2025",
        "years": 2,
        "count": 20,
        "avgMonthsApart": 1.2,
        "description": "Reasoning, agenter och multimodala genombrott"
      }
    ],
    "accelerationFactor": 75,
    "currentPace": "~1 milstolpe per m√•nad (2024-2025)",
    "totalMilestones": 55
  }
}
